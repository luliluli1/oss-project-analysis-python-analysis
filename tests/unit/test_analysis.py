import pytest
import pandas as pd
import os
from pathlib import Path
import tempfile
import shutil
import matplotlib
matplotlib.use('Agg')  # ç¡®ä¿ä½¿ç”¨éäº¤äº’å¼åç«¯

from src.analysis import analyze_commit_patterns

class TestAnalysis:
    """
    æµ‹è¯•åˆ†ææ¨¡å—çš„æ ¸å¿ƒåŠŸèƒ½
    """
    
    def setup_method(self):
        """ä¸ºæ¯ä¸ªæµ‹è¯•åˆ›å»ºéš”ç¦»çš„ä¸´æ—¶ç¯å¢ƒ"""
        # åˆ›å»ºä¸´æ—¶ç›®å½•
        self.test_dir = Path(tempfile.mkdtemp())
        self.test_output_dir = self.test_dir / "output"
        self.test_output_dir.mkdir(exist_ok=True)
        
        # åˆ›å»ºæµ‹è¯•æ•°æ®æ–‡ä»¶
        self.test_data_path = self.test_dir / "test_commits.csv"
        
        # åˆ›å»ºåŒ…å«å¿…è¦åˆ—çš„æµ‹è¯•æ•°æ®
        test_data = pd.DataFrame({
            'commit_hash': ['abc123', 'def456', 'ghi789', 'jkl012', 'mno345'],
            'author': ['Alice', 'Bob', 'Charlie', 'Alice', 'David'],
            'date': [
                '2025-01-11 10:30:00',
                '2025-01-12 14:45:00', 
                '2025-01-13 09:15:00',
                '2025-01-13 16:20:00',
                '2025-01-14 11:05:00'
            ],
            'message': [
                'Fix bug in authentication flow',
                'Add feature: user profile page',
                'Update documentation for API endpoints',
                'Refactor database connection logic',
                'Improve error handling in request module'
            ],
            'lines_added': [15, 42, 8, 23, 17],
            'lines_deleted': [3, 5, 2, 11, 4],
            'files_changed': [2, 3, 1, 4, 2]
        })
        
        # ä¿å­˜ä¸ºCSVæ–‡ä»¶
        test_data.to_csv(str(self.test_data_path), index=False)
        
        print(f"\nğŸ§ª æµ‹è¯•ç¯å¢ƒè®¾ç½®:")
        print(f"ä¸´æ—¶ç›®å½•: {self.test_dir}")
        print(f"æµ‹è¯•æ•°æ®æ–‡ä»¶: {self.test_data_path}")
        print(f"è¾“å‡ºç›®å½•: {self.test_output_dir}")
    
    def teardown_method(self):
        """æ¸…ç†æµ‹è¯•ç¯å¢ƒ"""
        try:
            if self.test_dir.exists():
                # å…³é—­æ‰€æœ‰matplotlibå›¾å½¢
                import matplotlib.pyplot as plt
                plt.close('all')
                # é€’å½’åˆ é™¤ä¸´æ—¶ç›®å½•
                shutil.rmtree(str(self.test_dir), ignore_errors=True)
            print("ğŸ§¹ æµ‹è¯•ç¯å¢ƒå·²æ¸…ç†")
        except Exception as e:
            print(f"âš ï¸  æ¸…ç†æµ‹è¯•ç¯å¢ƒæ—¶å‡ºé”™: {str(e)}")
    
    def test_analyze_commit_patterns_basic(self):
        """æµ‹è¯•åŸºæœ¬çš„æäº¤æ¨¡å¼åˆ†æåŠŸèƒ½"""
        print(f"\nğŸ” è¿è¡Œåˆ†æåŠŸèƒ½æµ‹è¯•...")
        
        try:
            # æ­£ç¡®è°ƒç”¨ï¼šä¼ å…¥æ–‡ä»¶è·¯å¾„å­—ç¬¦ä¸²
            result = analyze_commit_patterns(
                str(self.test_data_path),  # æ–‡ä»¶è·¯å¾„
                str(self.test_output_dir)  # è¾“å‡ºç›®å½•
            )
            
            # éªŒè¯è¿”å›ç»“æœ
            assert isinstance(result, pd.DataFrame), "åº”è¿”å›DataFrameå¯¹è±¡"
            assert len(result) > 0, "è¿”å›çš„DataFrameä¸åº”ä¸ºç©º"
            print(f"âœ… åˆ†ææˆåŠŸå®Œæˆï¼Œå¤„ç†äº† {len(result)} æ¡è®°å½•")
            
            # éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶
            self._verify_generated_files()
            
        except Exception as e:
            print(f"âŒ åˆ†ææ‰§è¡Œå¤±è´¥: {str(e)}")
            # æ£€æŸ¥è¾“å‡ºç›®å½•å†…å®¹
            if self.test_output_dir.exists():
                print("\nğŸ“ è¾“å‡ºç›®å½•å†…å®¹:")
                for item in self.test_output_dir.iterdir():
                    print(f"  - {item.name} (å¤§å°: {item.stat().st_size} å­—èŠ‚)")
            raise
    
    def _verify_generated_files(self):
        """éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶"""
        print("\nâœ… éªŒè¯ç”Ÿæˆçš„æ–‡ä»¶:")
        
        # å…³é”®æ–‡ä»¶ï¼ˆå¿…é¡»å­˜åœ¨ï¼‰
        critical_files = [
            ("analysis_report.md", "Markdownåˆ†ææŠ¥å‘Š"),
            ("processed_data.csv", "å¤„ç†åçš„æ•°æ®æ–‡ä»¶"),
            ("summary.txt", "æ‘˜è¦æ–‡ä»¶")
        ]
        
        # å›¾è¡¨æ–‡ä»¶ï¼ˆå¯èƒ½éƒ¨åˆ†å¤±è´¥ï¼Œä½†è‡³å°‘åº”ç”Ÿæˆå¤§éƒ¨åˆ†ï¼‰
        chart_files = [
            ("weekday_distribution.png", "æ˜ŸæœŸåˆ†å¸ƒå›¾"),
            ("hourly_distribution.png", "å°æ—¶åˆ†å¸ƒå›¾"),
            ("contributors_distribution.png", "è´¡çŒ®è€…åˆ†å¸ƒå›¾"),
            ("monthly_trends.png", "æœˆåº¦è¶‹åŠ¿å›¾"),
            ("message_types_pie.png", "æäº¤æ¶ˆæ¯ç±»å‹åˆ†å¸ƒå›¾"),
            ("code_structure_analysis.png", "ä»£ç ç»“æ„åˆ†æå›¾")
        ]
        
        # éªŒè¯å…³é”®æ–‡ä»¶
        critical_failures = 0
        for filename, description in critical_files:
            file_path = self.test_output_dir / filename
            if file_path.exists() and file_path.stat().st_size > 0:
                print(f"  âœ… {description}: {filename} (å¤§å°: {file_path.stat().st_size} å­—èŠ‚)")
            else:
                print(f"  âŒ {description} æœªç”Ÿæˆæˆ–ä¸ºç©º: {filename}")
                critical_failures += 1
        
        assert critical_failures == 0, f"å…³é”®æ–‡ä»¶éªŒè¯å¤±è´¥: {critical_failures} ä¸ªæ–‡ä»¶æœªç”Ÿæˆ"
        
        # éªŒè¯å›¾è¡¨æ–‡ä»¶
        successful_charts = 0
        failed_charts = []
        
        for filename, description in chart_files:
            file_path = self.test_output_dir / filename
            if file_path.exists() and file_path.stat().st_size > 1000:  # å›¾è¡¨åº”å¤§äº1KB
                print(f"  âœ… {description}: {filename} (å¤§å°: {file_path.stat().st_size} å­—èŠ‚)")
                successful_charts += 1
            else:
                status = "ä¸å­˜åœ¨" if not file_path.exists() else "æ–‡ä»¶è¿‡å°"
                print(f"  âš ï¸  {description} æœªæˆåŠŸç”Ÿæˆ: {filename} ({status})")
                failed_charts.append((filename, description))
        
        # æ£€æŸ¥å›¾è¡¨ç”Ÿæˆç‡
        success_rate = successful_charts / len(chart_files)
        print(f"\nğŸ“Š å›¾è¡¨ç”Ÿæˆç»Ÿè®¡: {successful_charts}/{len(chart_files)} ({success_rate:.1%})")
        
        # è‡³å°‘60%çš„å›¾è¡¨åº”æˆåŠŸç”Ÿæˆ
        assert success_rate >= 0.6, (
            f"å›¾è¡¨ç”Ÿæˆç‡è¿‡ä½: {success_rate:.1%} (<60%)\n"
            f"å¤±è´¥çš„å›¾è¡¨: {', '.join([desc for _, desc in failed_charts])}"
        )
        
        # ç‰¹åˆ«éªŒè¯æ ¸å¿ƒå›¾è¡¨
        core_charts = ["weekday_distribution.png", "hourly_distribution.png"]
        for chart in core_charts:
            chart_path = self.test_output_dir / chart
            assert chart_path.exists() and chart_path.stat().st_size > 1000, (
                f"æ ¸å¿ƒå›¾è¡¨æœªç”Ÿæˆ: {chart}"
            )
        
        print(f"ğŸ‰ æ‰€æœ‰æ–‡ä»¶éªŒè¯é€šè¿‡! æ€»å…±ç”Ÿæˆäº† {len(list(self.test_output_dir.iterdir()))} ä¸ªæ–‡ä»¶")

    def test_analysis_with_minimal_data(self):
        """æµ‹è¯•ä½¿ç”¨æœ€å°æ•°æ®é›†çš„åˆ†æåŠŸèƒ½"""
        print("\nğŸ” æµ‹è¯•æœ€å°æ•°æ®é›†åˆ†æ...")
        
        # åˆ›å»ºæœ€å°æµ‹è¯•æ•°æ®
        minimal_data = pd.DataFrame({
            'commit_hash': ['min123'],
            'author': ['TestUser'],
            'date': ['2025-01-15 08:30:00'],
            'message': ['Minimal test commit'],
            'lines_added': [1],
            'lines_deleted': [0],
            'files_changed': [1]
        })
        
        minimal_path = self.test_dir / "minimal_test.csv"
        minimal_data.to_csv(str(minimal_path), index=False)
        
        output_dir = self.test_dir / "minimal_output"
        output_dir.mkdir(exist_ok=True)
        
        try:
            result = analyze_commit_patterns(
                str(minimal_path),
                str(output_dir)
            )
            
            assert isinstance(result, pd.DataFrame)
            assert len(result) == 1
            
            # éªŒè¯è‡³å°‘ç”Ÿæˆäº†å…³é”®æ–‡ä»¶
            required_files = ["analysis_report.md", "processed_data.csv"]
            for filename in required_files:
                file_path = output_dir / filename
                assert file_path.exists(), f"å…³é”®æ–‡ä»¶æœªç”Ÿæˆ: {filename}"
                assert file_path.stat().st_size > 0, f"æ–‡ä»¶ä¸ºç©º: {filename}"
            
            print("âœ… æœ€å°æ•°æ®é›†æµ‹è¯•é€šè¿‡")
            
        except Exception as e:
            print(f"âŒ æœ€å°æ•°æ®é›†æµ‹è¯•å¤±è´¥: {str(e)}")
            if output_dir.exists():
                print("\nğŸ“ æœ€å°æ•°æ®é›†è¾“å‡ºå†…å®¹:")
                for item in output_dir.iterdir():
                    print(f"  - {item.name} (å¤§å°: {item.stat().st_size} å­—èŠ‚)")
            raise